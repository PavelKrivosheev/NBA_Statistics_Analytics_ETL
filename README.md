# nba_stats
Pet-проект
Проект направлен на автоматизацию обработки и анализа баскетбольной статистики НБА для предоставления аналитических отчётов по эффективности игроков и команд. Использованы технологии Python, Apache Airflow, PostgreSQL и Metabase для создания ETL-пайплайна, хранилища данных (DWH) и интерактивных дашбордов. 
Проект решает задачу автоматизации сбора, обработки и анализа статистики НБА для предоставления аналитикам и тренерам удобных инструментов для оценки эффективности игроков и команд. Цель — создать надёжный ETL-пайплайн и аналитические витрины, интегрированные с BI-инструментом Metabase, для быстрого доступа к ключевым метрикам, таким как процент попаданий, очки за игру и вклад трёхочковых бросков.
Репозиторий nba_stats представляет собой ETL-пайплайн (Extract, Transform, Load) для обработки данных NBA (статистика игроков, команд, игр и т.д.), реализованный с использованием Apache Airflow и Docker. Данные извлекаются из различных источников (SQLite, CSV, API), обрабатываются и загружаются в PostgreSQL базу данных, организованную по слоям (staging, DDS, DM). Проект ориентирован на автоматизированную обработку и анализ баскетбольной статистики, включая такие аспекты, как статистика игроков по зонам бросков, командные показатели и исторические данные драфта.

Основные компоненты
Airflow DAGs:
dag_load_static.py: Загружает статические таблицы (например, common_player_info, player, team) из SQLite в staging-слой PostgreSQL.
dag_load_dds.py: Обрабатывает данные из staging-слоя, загружая их в DDS (Data Delivery Store) слой с использованием SCD2 (Slowly Changing Dimension Type 2) для отслеживания изменений.
dag_load_shot_data.py: Загружает данные о бросках (shot data) из CSV в staging-слой и затем в DDS/DM слои.
dag_load_dm.py: Формирует витрины данных (data marts) в DM-слое для аналитики, например, статистика игроков по зонам бросков.
Скрипты:
load_static_tables.py: Логика синхронизации статических таблиц между SQLite и PostgreSQL (описана в предыдущем вашем вопросе).
load_dds_tables.py: Логика загрузки данных в DDS-слой с поддержкой SCD2.
load_shot_data.py: Обработка CSV-файлов с данными о бросках.
utils.py: Вспомогательные функции, такие как логирование, проверка качества данных и SQL-запросы.
Конфигурация:
docker-compose.yml: Определяет сервисы для Airflow, PostgreSQL.
.env: Переменные окружения (например, пути к данным, параметры подключения).
requirements.txt: Зависимости Python (Airflow, psycopg2, pandas и т.д.).
Данные:
SQLite база (data/nba.sqlite): Источник статических данных (игроки, команды, драфт).
CSV-файлы (data/shot_data/): Данные о бросках игроков.
PostgreSQL: Целевая база для хранения данных в слоях staging, DDS и DM.
Логика работы:
Staging: Временное хранилище сырых данных из SQLite и CSV.
DDS: Нормализованные таблицы с историей изменений (SCD2).
DM: Витрины данных для аналитики (например, dm_player_zone_stats).
Airflow оркестрирует процесс, запуская задачи в правильной последовательности.
